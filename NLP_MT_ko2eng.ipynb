{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import os \n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "  drive.mount('/content/drive')\n",
    "except:\n",
    "  IN_COLAB = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801387,)\n",
      "(801387,)\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    data_path = \"\"\n",
    "else:\n",
    "    data_path = \"dataset/ko2eng\"\n",
    "\n",
    "x = np.array([])\n",
    "y = np.array([])\n",
    "\n",
    "for fname in sorted(os.listdir(data_path)):\n",
    "    src_input_ids = os.path.join(data_path, fname)\n",
    "    df = pd.read_excel(src_input_ids)\n",
    "    x = np.concat((x, df['원문'].values))\n",
    "    y = np.concat((y, df['번역문'].values))\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x max: 220\n",
      "x mean: 69.15487149155152\n",
      "x median: 71.0\n",
      "freq top 5: [[   70 18371]\n",
      " [   68 18287]\n",
      " [   69 18245]\n",
      " [   71 18199]\n",
      " [   73 17843]]\n",
      "y max: 706\n",
      "y mean: 173.24487170368374\n",
      "y median: 174.0\n",
      "freq top 5: [[ 171 5306]\n",
      " [ 179 5263]\n",
      " [ 181 5254]\n",
      " [ 175 5238]\n",
      " [ 183 5222]]\n"
     ]
    }
   ],
   "source": [
    "x_len_array = [len(sentence) for sentence in x]\n",
    "y_len_array = [len(sentence) for sentence in y]\n",
    "\n",
    "unique_x, counts_x = np.unique(x_len_array, return_counts=True)\n",
    "freq_x = np.column_stack((unique_x, counts_x))\n",
    "sorted_freq_x = freq_x[freq_x[:, 1].argsort()[::-1]]\n",
    "\n",
    "unique_y, counts_y = np.unique(y_len_array, return_counts=True)\n",
    "freq_y = np.column_stack((unique_y, counts_y))\n",
    "sorted_freq_y = freq_y[freq_y[:, 1].argsort()[::-1]]\n",
    "\n",
    "print(\"x max:\", np.max(x_len_array))\n",
    "print(\"x mean:\", np.mean(x_len_array))\n",
    "print(\"x median:\", np.median(x_len_array))\n",
    "print(\"freq top 5:\", sorted_freq_x[:5])\n",
    "\n",
    "print(\"y max:\", np.max(y_len_array))\n",
    "print(\"y mean:\", np.mean(y_len_array))\n",
    "print(\"y median:\", np.median(y_len_array))\n",
    "print(\"freq top 5:\", sorted_freq_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_150 max: 149\n",
      "x_150 max: 142\n",
      "['스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.' '심지어 어떤 문제가 발생할 건지도 어느 정도 예측이 가능하다.'\n",
      " '오직 하나님만이 그 이유를 제대로 알 수 있을 겁니다.' ...\n",
      " '아직 시즌 초반이라 더 지켜봐야 하지만 최근 몇 년간 라리가를 지배했던 그 힘은 보이지 않는 게 사실이다.'\n",
      " '인도에 제설작업이 잘 됐는지 살펴보기 위해 호텔 정문을 나서니 호텔 이름이 새겨진 승합차가 서 있는 것이 눈에 들어온다.'\n",
      " '영화 ‘지금 만나러 갑니다’는 비가 오는 날 다시 돌아오겠다던 약속을 남기고 떠난 수아(손예진 분)와 그녀를 기다리는 우진(소지섭 분)의 이야기다.']\n",
      "[\"Skinner's reward is mostly eye-watering.\"\n",
      " 'Even some problems can be predicted.' 'Only God will exactly know why.'\n",
      " ...\n",
      " \"It's still early in the season, so it remains to be seen but it is true that La Liga is not strong as much as that it used to be in recent years.\"\n",
      " 'As I left the main gate of the hotel to see if the snow removal work had gone well on the sidewalks, I could see a van with the hotel’s name on it.'\n",
      " \"The movie, 'Be With You' is about a story of Sua (Son Ye Jin) and Ujin (So Ji Sup) waiting for her who left a promise to come back on a rainy day.\"]\n",
      "281539\n",
      "281539\n"
     ]
    }
   ],
   "source": [
    "y_len_np = np.array(y_len_array)\n",
    "x_len_np = np.array(x_len_array)\n",
    "\n",
    "\n",
    "print(\"y_150 max:\", np.max(y_len_np[y_len_np < 150]))\n",
    "print(\"x_150 max:\", np.max(x_len_np[y_len_np < 150]))\n",
    "\n",
    "x_max_150 = x[y_len_np < 150]\n",
    "y_max_150 = y[y_len_np < 150]\n",
    "\n",
    "print(x_max_150)\n",
    "print(y_max_150)\n",
    "print(len(x_max_150))\n",
    "print(len(y_max_150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.\n",
      "['[CLS]', '스', '##키', '##너', '##가', '말한', '보상', '##은', '대부분', '눈', '##으로', '볼', '수', '있는', '현', '##물이', '##다', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[3, 1538, 2465, 2849, 2418, 8352, 9919, 2451, 4739, 858, 4359, 1327, 1507, 4368, 2314, 4820, 2400, 17, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "스키너가 말한 보상은 대부분 눈으로 볼 수 있는 현물이다.\n",
      "Skinner's reward is mostly eye-watering.\n",
      "['[CLS]', 'S', '##k', '##in', '##n', '##er', \"'\", 's', 'r', '##e', '##w', '##ar', '##d', 'i', '##s', 'm', '##o', '##st', '##l', '##y', 'e', '##y', '##e', '-', 'w', '##at', '##er', '##in', '##g', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[3, 54, 2867, 6916, 2414, 6574, 10, 84, 83, 2413, 3058, 7545, 2976, 74, 2546, 78, 2545, 9263, 3006, 3052, 70, 3052, 2413, 16, 88, 8366, 6574, 6916, 2661, 17, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Skinner ' s reward is mostly eye - watering.\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, decoders, models, normalizers, pre_tokenizers, trainers, processors\n",
    "\n",
    "\n",
    "def train_tokenizer(src, vocab_size, special_token, max_len):\n",
    "    tokenizer = Tokenizer(models.WordPiece())\n",
    "    tokenizer.normalizer = normalizers.NFKC()\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "    tokenizer.post_processor = processors.BertProcessing(sep=('[SEP]', 2), cls=('[CLS]', 3))\n",
    "    tokenizer.decoder = decoders.WordPiece()\n",
    "    token_trainer = trainers.WordPieceTrainer(\n",
    "        vocab_size = vocab_size,\n",
    "        special_tokens=special_token,\n",
    "        show_progress=True,\n",
    "    )\n",
    "\n",
    "    tokenizer.train_from_iterator(src, trainer=token_trainer)\n",
    "    tokenizer.enable_truncation(max_len)\n",
    "    tokenizer.enable_padding(length=max_len)\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "\n",
    "# [\"[PAD]\", \"[UNK]\", \"[SEP]\", \"[CLS]\"]\n",
    "vocab_size = 10000\n",
    "special_token = [\"[PAD]\", \"[UNK]\", \"[SEP]\", \"[CLS]\"]\n",
    "max_len = 150\n",
    "src_tokenizer = train_tokenizer(x_max_150, vocab_size, special_token, max_len)\n",
    "tgt_tokenizer = train_tokenizer(y_max_150, vocab_size, special_token, max_len)\n",
    "\n",
    "print(x_max_150[0])\n",
    "temp = src_tokenizer.encode(x_max_150[0]) \n",
    "print(temp.tokens)\n",
    "print(temp.ids)\n",
    "print(src_tokenizer.decode(temp.ids))\n",
    "\n",
    "print(y_max_150[0])\n",
    "temp = src_tokenizer.encode(y_max_150[0]) \n",
    "print(temp.tokens)\n",
    "print(temp.ids)\n",
    "print(src_tokenizer.decode(temp.ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensors = torch.tensor(np.array([src_tokenizer.encode(entry).ids for entry in x_max_150]))\n",
    "y_tensors = torch.tensor(np.array([tgt_tokenizer.encode(entry).ids for entry in y_max_150]))\n",
    "\n",
    "dataset = TensorDataset(x_tensors, y_tensors)\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset=dataset, lengths=[0.7, 0.15, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, config) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = config['d_model'] if 'd_model' in config else 512\n",
    "        self.n_head = config['n_head'] if 'n_head' in config else 8\n",
    "        self.n_encoder = config['n_encoder'] if 'n_encoder' in config else 6\n",
    "        self.n_decoder = config['n_decoder'] if 'n_decoder' in config else 6\n",
    "        self.hidden_size = config['hidden_size'] if 'hidden_size' in config else 512\n",
    "        self.seq_len = config['seq_len']\n",
    "        self.device = config['device']\n",
    "\n",
    "        self.src_embed = nn.Embedding(config['src_vocab_size'], embedding_dim=self.d_model)\n",
    "        self.tgt_embed = nn.Embedding(config['tgt_vocab_size'], embedding_dim=self.d_model)\n",
    "\n",
    "        \n",
    "        self.pos_embed = PositionalEncoding(d_model=self.d_model, device=self.device)\n",
    "        self.padding_mask = PaddingMask(pad_id=config['pad_id'])\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=self.d_model,\n",
    "            nhead=self.n_head,\n",
    "            num_encoder_layers=self.n_encoder,\n",
    "            num_decoder_layers=self.n_decoder,\n",
    "        )\n",
    "\n",
    "\n",
    "        # tgt_mask : [dec_seq, dec_seq] : 출력 Sequence Attention Mask (Trm decoding을 위한 계단식 MASK)\n",
    "        # tgt_mask 입력 길이 L에 대한 (L X L) mask 생성. torch.triu 사용. (생성된 값만 보게끔 하는 부분)\n",
    "        self.tgt_mask = torch.triu( torch.ones([self.seq_len, self.seq_len])).T.to(self.device)\n",
    "\n",
    "        self.projection_layer_1 = nn.Linear(self.d_model, self.hidden_size)\n",
    "        self.activation = nn.GELU()\n",
    "        self.projection_layer_2 = nn.Linear(self.hidden_size, config['tgt_vocab_size'])\n",
    "\n",
    "\n",
    "    def forward(self, src_input_ids, tgt_input_ids, \n",
    "                src_key_padding_mask = None, tgt_key_padding_mask = None):\n",
    "        \n",
    "        # src_input_ids: (batch, seq_len)\n",
    "        # target_input_ids: (batch, seq_len)\n",
    "        \n",
    "        encoder_input_feature = self.src_embed(src_input_ids)\n",
    "        # encoder_input_feuatre: (batch, seq_len, embedding)\n",
    "        encoder_input_feature = encoder_input_feature.transpose(0, 1)\n",
    "        # pos_embed worked based on seq_len, batch, embeding\n",
    "        encoder_input_feature = self.pos_embed(encoder_input_feature)\n",
    "        \n",
    "        # same as encoder input handling\n",
    "        decoder_input_feature = self.tgt_embed(tgt_input_ids)\n",
    "        decoder_input_feature = decoder_input_feature.transpose(0, 1)\n",
    "        decoder_input_feature = self.pos_embed(decoder_input_feature)\n",
    "\n",
    "        # src : [enc_seq, batch, hidden]\n",
    "        # tgt : [dec_seq, batch, hidden]\n",
    "        \n",
    "        # src_mask : [enc_seq, enc_seq] : 입력 Sequence Attention Mask (일반적으로 사용하지 않음)\n",
    "        \n",
    "        \n",
    "        # src_key_padding_mask : [batch, enc_seq] : 입력 Padding Mask\n",
    "        src_key_padding_mask = self.padding_mask(src_input_ids)\n",
    "\n",
    "        # tgt_key_padding_mask : [batch, dec_seq] : 출력 Padding Mask\n",
    "        tgt_key_padding_mask = self.padding_mask(tgt_input_ids)\n",
    "\n",
    "        # src_mask는 일반적으로 구현 x\n",
    "        # src_key_padding_mask : masked_fill 이용해서 생성\n",
    "        # tgt_key_padding_mask\n",
    "        \n",
    "        out = self.transformer(encoder_input_feature, decoder_input_feature, \n",
    "                               src_mask=None, tgt_mask=self.tgt_mask,\n",
    "                               src_key_padding_mask=src_key_padding_mask,\n",
    "                               tgt_key_padding_mask=tgt_key_padding_mask,)\n",
    "        \n",
    "        out = self.projection_layer_1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.projection_layer_2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, device, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.to(device)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class PaddingMask(nn.Module):\n",
    "    def __init__(self, pad_id) -> None:\n",
    "        super().__init__()\n",
    "        self.pad_id = pad_id\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.masked_fill(x == self.pad_id, 1).masked_fill(x != self.pad_id, 0).bool()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, config, model, train_dl, val_dl, criterion, optimizer) -> None:\n",
    "        self.model_name = model.__class__.__name__\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.train_dl = train_dl\n",
    "        self.val_dl = val_dl\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.device = config['device'] if 'device' in config else \"cpu\"\n",
    "        self.num_of_epoch = config['epoch'] if 'epoch' in config else 10\n",
    "        self.lr = config['learning_rate'] if 'learning_rate' in config else 1e-2\n",
    "        self.patience = config['patience'] if 'patience' in config else 5\n",
    "        self.output_dir = config['output'] if 'output' in config else \"output/\"\n",
    "\n",
    "    def train(self):\n",
    "        train_loss_history = []\n",
    "        train_accuracy_history = []\n",
    "        val_loss_history = []\n",
    "        val_accuarcy_history = []\n",
    "\n",
    "        self.model = self.model.to(self.device)\n",
    "        best_epoch = 0\n",
    "        best_loss = np.inf\n",
    "        epochs_no_improve = 0\n",
    "        buffer = io.BytesIO()\n",
    "        \n",
    "\n",
    "        for epoch in range(self.num_of_epoch):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0\n",
    "            total_count = 0\n",
    "            pbar = tqdm(self.train_dl, desc=f\"epoch[{epoch+1}]\")\n",
    "\n",
    "            for step, batch in enumerate(pbar):\n",
    "                x = batch[0].to(self.device)\n",
    "                y = batch[1].to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                y_pred = self.model(x, y)\n",
    "\n",
    "                # y_pred ( seq_len, batch, feature_num )\n",
    "                y_pred_compare = torch.reshape(y_pred, (-1, y_pred.shape[-1]))\n",
    "                # y ( batch, seq_len )\n",
    "                y_target = torch.reshape(y, (-1,))\n",
    "\n",
    "                loss = self.criterion(y_pred_compare, y_target)\n",
    "                epoch_loss += loss.item() * y_target.shape[0]\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_count += y_target.shape[0]\n",
    "\n",
    "            epoch_loss_mean = epoch_loss / total_count\n",
    "            val_loss_mean = self.validation()\n",
    "            pbar.set_postfix_str(f\"train_loss={epoch_loss_mean:.5f}, val_loss={val_loss_mean:.5f}\")\n",
    "            \n",
    "            train_loss_history.append(epoch_loss_mean)\n",
    "            val_loss_history.append(val_loss_mean)\n",
    "\n",
    "            if val_loss_mean < best_loss:\n",
    "                best_loss = val_loss_mean\n",
    "                epochs_no_improve = 0\n",
    "                best_epoch = epoch\n",
    "                \n",
    "                buffer.seek(0)\n",
    "                buffer.truncate()\n",
    "                torch.save(self.model.state_dict(), buffer)\n",
    "                buffer.seek(0)\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "\n",
    "            if epochs_no_improve >= self.patience:\n",
    "                print(f'Early stopping at epoch {epoch}')\n",
    "                break\n",
    "        \n",
    "        output_path = os.path.join(self.output_dir, f\"{self.model_name}_ep_{best_epoch}_loss_{best_loss:.4f}.pt\")\n",
    "        print(output_path)\n",
    "        with open(output_path, mode='wb') as f:\n",
    "            f.write(buffer.getbuffer())\n",
    "\n",
    "        return (train_loss_history, train_accuracy_history, val_loss_history, val_accuarcy_history), output_path\n",
    "\n",
    "    def validation(self):\n",
    "        return self.test(self.model, self.val_dl)\n",
    "\n",
    "    def test(self, model, dataloader):\n",
    "        model.eval()\n",
    "        epoch_loss = 0\n",
    "        for _, batch in enumerate(dataloader):\n",
    "            x = batch[0].to(self.device)\n",
    "            y = batch[1].to(self.device)\n",
    "\n",
    "            y_pred = self.model(x)\n",
    "            # y_pred ( seq_len, batch, feature_num )\n",
    "            y_pred_compare = torch.reshape(y_pred, (-1, y_pred.shape[-1]))\n",
    "            # y ( batch, seq_len )\n",
    "            y_target = torch.reshape(y, (-1,))\n",
    "\n",
    "            loss = self.criterion(y_pred_compare, y_target)\n",
    "        \n",
    "            epoch_loss += loss.item() * y_target.shape[0]\n",
    "\n",
    "            total_count += y_target.shape[0]\n",
    "        \n",
    "        epoch_loss_mean = epoch_loss / total_count\n",
    "\n",
    "        return epoch_loss_mean\n",
    "                        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jingi/mambaforge/envs/torch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "epoch[1]:   0%|          | 0/3080 [00:00<?, ?it/s]/home/jingi/mambaforge/envs/torch/lib/python3.10/site-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "epoch[1]: 100%|██████████| 3080/3080 [14:58<00:00,  3.43it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'val_dataloader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[1;32m     21\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(config, model, train_dl, val_dl, criterion, optimizer)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 59\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m     total_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y_target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     58\u001b[0m epoch_loss_mean \u001b[38;5;241m=\u001b[39m epoch_loss \u001b[38;5;241m/\u001b[39m total_count\n\u001b[0;32m---> 59\u001b[0m val_loss_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss_mean\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss_mean\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m train_loss_history\u001b[38;5;241m.\u001b[39mappend(epoch_loss_mean)\n",
      "Cell \u001b[0;32mIn[9], line 89\u001b[0m, in \u001b[0;36mTrainer.validation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_dataloader\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'val_dataloader'"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'batch_size':batch_size,\n",
    "    'src_vocab_size':src_tokenizer.get_vocab_size(),\n",
    "    'tgt_vocab_size':tgt_tokenizer.get_vocab_size(),\n",
    "    'd_model':512,\n",
    "    'n_head':8,\n",
    "    'n_encoder':6,\n",
    "    'n_decoder':6,\n",
    "    'hidden_size':512,\n",
    "    'pad_id':0,\n",
    "    'dropout':0.1,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else \"cpu\",\n",
    "    'epoch': 100,\n",
    "    'learning_rate':1e-3,\n",
    "    'seq_len':150,\n",
    "}\n",
    "\n",
    "model = TransformerModel(config)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "trainer = Trainer(config, model, train_dl, val_dl, criterion, optimizer)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
